{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235b5373-fd55-42b3-ae9a-262eab626931",
   "metadata": {},
   "source": [
    "# 인스타 데이터 수집_v2\n",
    "\n",
    "## 외부지표\n",
    "(프로필 정보 관련) ID, 게시물 수, 팔로워 수, 팔로우 수, 카테고리, 자기소개  \n",
    "(각 게시물 정보 관련) 좋아요 수, 댓글 수  \n",
    "(보류) 게시글 내용, 댓글 내용  \n",
    "\n",
    "## 추가한 기능\n",
    "- sample_.csv 파일을 불러들여 각 url과 인플루언서 선정 변수 값을 받을 수 있게 코드 구성.\n",
    "- 게시물 수 만큼 행 데이터를 만들어서 csv 파일로 도출.\n",
    "- 이미지 데이터들을 로컬 컴퓨터에 저장하는 기능 추가.\n",
    "\n",
    "## 코드 참고 사항\n",
    "### 좋아요 개수 추출에서 생기는 문제\n",
    "사용자의 좋아요 수를 공개 여부에 따라 선택자 명과 태그 구조가 달라집니다.  \n",
    "최대한 타협안으로 좋아요 개수 전체 태그의 클래스 명을 사용했습니다.  \n",
    "그래서 좋아요 개수뿐만 아니라 글자도 같이 포함되는데 이는 파이썬 전처리로 해결해야 될 것 같습니다.  \n",
    "\n",
    "- 좋아요 개수 공개했을 때 사용할 선택자 명: \"._ae5m .html-span\"  \n",
    "- 좋아요 개수 공개하지 않을 때 사용할 선택자 명: \"._ae5m a:nth-child(2)\"  \n",
    "- 이 코드에서는 상위 태그인 \"._ae5m .x193iq5w.xeuugli\"를 사용했습니다.\n",
    "\n",
    "### 로딩 시간에 따른 오류 발생 가능\n",
    "로딩 시간 문제로 webdriver가 선택자를 잘 파악하지 못할 수도 있습니다.  \n",
    "일단 selenium webdriver 함수 동작 이후마다 대기 시간을 줌으로써 오류를 줄여보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a6ba1-e42d-4f8e-829c-407d3b4158b1",
   "metadata": {},
   "source": [
    "## 실행 시 주의!!\n",
    "- 크롬 드라이버를 다운받고 이 코드 파일와 동일한 경로에 넣어 주세요.\n",
    "- 이 코드 창을 브라우저 크기를 줄이고 코드 실행해야 잘 작동합니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de25f91-4391-4852-a970-6a1ecf883f0b",
   "metadata": {},
   "source": [
    "## 1. 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457dec0-51d1-4db0-a83d-1ff1ec663a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install webdriver_manager\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb3ad4-88e0-4f11-8801-245dd6a782f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager # 크롬 드라이버 자동 업데이트을 위한 모듈\n",
    "\n",
    "import urllib.request # 이미지 저장 라이브러리\n",
    "\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe31a4df-256b-42d5-a0a5-bd72bd0d69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_.csv 불러오기\n",
    "sample = pd.read_csv('sample_.csv')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226b4ca-1b5a-4624-8cb2-681415511d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열만 추출\n",
    "subset = sample[['check', 'link']]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a9164-769b-4530-9af2-f1337dd0442f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checks = list(subset['check'])\n",
    "links = list(subset['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6eecc6-f965-4361-b04e-6a8cd3a115e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롬 드라이버 옵션 관련 코드\n",
    "\n",
    "# 브라우저 꺼짐 방지 옵션\n",
    "options = Options()\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "options.add_argument('window-size=1920x1080') # pc용 사이즈\n",
    "options.add_argument('--start-maximized')     # 브라우저가 최대화된 상태로 실행\n",
    "\n",
    "# 크롤링 차단 방지를 위한 user-agent 기입 (접속에 오류가 날 경우)\n",
    "# options.add_argument(\"user-agent=본인의user-agent\")\n",
    "# user-agent=는 띄어쓰지 말고 꼭 붙여쓰기\n",
    "\n",
    "# 불필요한 에러 메시지 삭제\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "\n",
    "# 크롬 드라이버 최신 버전 설정\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1b072-ed86-4ec8-8381-e31e7b917a38",
   "metadata": {},
   "source": [
    "driver 객체의 page_source라는 인스턴스 변수: 웹 서버로부터 전달받은 HTML 코드가 저장되어 있음.  \n",
    "\n",
    "1. selenium에서 page_source를 사용하여 해당 페이지의 소스, html을 가져오고 \n",
    "2. 가져온 html을 BeautifulSoup으로 넘겨줌.\n",
    "   \n",
    "이를 통해 페이지 이동 및 동작은 selenium으로 크롬 드라이버를 조작하여 할 수 있고,  \n",
    "원하는 페이지로 이동후 html을 BeatifulSoup으로 전달하여 원하는 웹 데이터를 가져와 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7653f3-7859-421c-8eb5-1957143b69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인스타그램 접속\n",
    "driver.get('https://instagram.com')\n",
    "\n",
    "# 인스타그램 자동 로그인\n",
    "time.sleep(2)\n",
    "login_id = driver.find_element(By.CSS_SELECTOR, 'input[name=\"username\"]')\n",
    "login_id.send_keys('본인의 인스타 아이디 입력')\n",
    "driver.implicitly_wait(10) # 나타날 때까지 최대 10초동안 기다리기\n",
    "login_pwd = driver.find_element(By.CSS_SELECTOR, 'input[name=\"password\"]')\n",
    "driver.implicitly_wait(10)\n",
    "login_pwd.send_keys('본인의 인스타 비밀번호 입력')\n",
    "time.sleep(2)\n",
    "login_id.send_keys(Keys.ENTER)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ace999-5e4f-4ada-821b-2e7fd75564a9",
   "metadata": {},
   "source": [
    "## 2 & 3. 데이터 수집 및 csv 파일 저장\n",
    "\n",
    "### 2. 프로필 관련 정보: 팔로워, 팔로잉, 게시물 수, 닉네임, 자기소개\n",
    "- bs4로 html문서를 읽어 수집\n",
    "\n",
    "### 3. 각 게시물 관련 정보: 좋아요 수, 댓글 수  \n",
    "-  셀레니움으로 게시물을 클릭해 이동하며 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d431a28-4204-43d2-8ab8-973977b6c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필드명 지정\n",
    "fieldnames = ['id', 'media_count', 'followers_count', 'follows_count', 'category', 'introduction', 'main_img', 'like_count', 'check']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53834b-ef4e-4257-8e64-4a1c063484b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawling.csv 라는 파일 생성하고 상단에 컬럼 이름 적기\n",
    "f = open('crawling.csv', 'w', newline='', encoding='utf-8')\n",
    "writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "\n",
    "# 반복문으로 각 인플루언서 주소에 접속\n",
    "for j in range(4): # 상위부터 4개까지의 계정을 가져옴\n",
    "\n",
    "    # sample_에서 추출한 데이터 가져오기\n",
    "    link = links[j]   # 해당 순서 사용자의 주소\n",
    "    check = checks[j] # 해당 순서 사용자의 인플루언서 여부\n",
    "\n",
    "    ##### 2. 프로필 관련 정보 가져오기 #####\n",
    "    driver.get(links[j])             # 페이지 이동\n",
    "    time.sleep(random.uniform(3, 4)) # 설정한 초 간격 사이로 랜덤하게 쉬기\n",
    "    \n",
    "    html = driver.page_source # html(페이지 소스) 가져오기\n",
    "    time.sleep(random.uniform(3, 4))\n",
    "    \n",
    "    soup = BeautifulSoup(html)\n",
    "    time.sleep(random.uniform(2, 3))\n",
    "\n",
    "    id = soup.select_one('h2').text # 사용자 id\n",
    "    \n",
    "    profile = soup.select(\"._ac2a > span\")\n",
    "    media_count = profile[0].text          # 게시물 수\n",
    "    followers_count = profile[1].text      # 팔로워 수\n",
    "    follows_count = profile[2].text        # 팔로우 수 \n",
    "    \n",
    "    try: \n",
    "        category = soup.select_one(\"._aacy\").text     # 카테고리\n",
    "    except:\n",
    "        category = 'NA' # 존재하지 않음을 표기\n",
    "    \n",
    "    try: \n",
    "        introduction = soup.select_one(\"._aacx\").text # 자기소개\n",
    "    except:\n",
    "        introduction = 'NA'\n",
    "\n",
    "    ##### 3. 각 게시물들의 대표 이미지와 좋아요 수 가져오기 #####\n",
    "    # 첫번째 게시물 클릭\n",
    "    time.sleep(random.uniform(1, 2))\n",
    "    driver.find_element(By.CSS_SELECTOR, '._aagu').click()\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    # 첫번째 게시물부터 데이터를 추출하고 다음 게시물을 클릭\n",
    "    for i in range(5): # 이 숫자를 조절하면 원하는 게시물 수만큼 가져올 수 있음\n",
    "        \n",
    "        # 예외처리로 일단 사진만 가져오게 하고 영상은 지나치도록 함\n",
    "        try:\n",
    "            # 대표 이미지 가져오기\n",
    "            main_img = driver.find_element(By.CSS_SELECTOR, \"._aagu._aato img\").get_attribute(\"src\")\n",
    "            #print(f'{id}의 {i}번째 게시물 이미지: ' + main_img)\n",
    "    \n",
    "            # 좋아요 수\n",
    "            like_count = driver.find_element(By.CSS_SELECTOR, \"._ae5m .x193iq5w.xeuugli\").text # 좋아요 수 영역\n",
    "            #print(f'{id}의 {i}번째 게시물 좋아요 수: ' + like_count)\n",
    "    \n",
    "            driver.find_element(By.CSS_SELECTOR, '._aaqg._aaqh').click() # 다음 버튼 클릭\n",
    "            time.sleep(random.uniform(1, 2))\n",
    "    \n",
    "        except:\n",
    "            # 영상은 지나치기 \n",
    "            main_img = 'NA'\n",
    "            #print(f'{id}의 {i}번째 게시물' + \"은 video입니다.\")\n",
    "            \n",
    "            # 좋아요 수\n",
    "            like_count = driver.find_element(By.CSS_SELECTOR, \"._ae5m .x193iq5w.xeuugli\").text\n",
    "            #print(f'{id}의 {i}번째 게시물 좋아요 수: ' + like_count)\n",
    "    \n",
    "            driver.find_element(By.CSS_SELECTOR, '._aaqg._aaqh').click() # 다음 버튼 클릭\n",
    "            time.sleep(random.uniform(1, 2))\n",
    "    \n",
    "        #print()\n",
    "\n",
    "        # 각 컬럼에 해당하는 값들을 기입해 하나의 행 데이터를 만들기\n",
    "        writer.writerow({'id': id, 'media_count': media_count, 'followers_count': followers_count, 'follows_count': follows_count, \n",
    "                         'category': category, 'introduction': introduction, 'main_img': main_img, 'like_count': like_count, 'check': check})\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "    \n",
    "    # 게시물 창 닫기\n",
    "    driver.find_element(By.CSS_SELECTOR, '.x160vmok line').click()\n",
    "    time.sleep(random.uniform(2, 3))\n",
    "    \n",
    "# csv 파일 작성 끝나면 닫기\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5939d9-55fa-47aa-b258-a3768491ea79",
   "metadata": {},
   "source": [
    "## 4. 이미지를 로컬 컴퓨터에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b7d22-5c8c-4863-afa7-567015d1206c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 만든 crawling.csv 불러오기\n",
    "result = pd.read_csv('crawling.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c68d58-7dcb-4ed3-808a-e6c12b9194d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_ls = list(result[\"main_img\"])\n",
    "img_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0220e8f-a9e6-45f9-b838-583e8fc5c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 이미지 파일 저장\n",
    "for k in range(len(img_ls)):\n",
    "\n",
    "    # 이미지 경로가 존재하지 않을 경우 -> 저장하는 단계 없이 넘어가기 \n",
    "    if type(img_ls[k]) == float: # 주의: nan값의 타입이 float임\n",
    "        print(f\"{k}번째 행은 이미지가 존재하지 않음\")\n",
    "        continue\n",
    "\n",
    "    # 이미지 경로가 존재할 경우 -> 아마지 저장하기 (저장명은 행 인덱스 번호로 지정)\n",
    "    urllib.request.urlretrieve(img_ls[k], \"이미지를 저장할 폴더 경로\" + \"0\"*(3-len(str(k)))+str(k) + \".jpg\") \n",
    "    # .urlretrieve(저장할 이미지의 원래 경로, 내 컴퓨터에 저장할 경로의 이름)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
